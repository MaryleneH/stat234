\documentclass{beamer}
\usepackage{amsmath,algorithm,algorithmic,graphicx,amsfonts,amsthm,color,pgf,tikz,wrapfig,amsfonts,multicol,wasysym,animate, appendixnumberbeamer}
\beamertemplatenavigationsymbolsempty
\useoutertheme[subsection=false]{miniframes}
\usetheme[progressbar=frametitle]{metropolis}
\metroset{block=fill}

\providecommand{\code}[1]{}
\renewcommand{\code}[1]{{\color{blue!80!black}\texttt{#1}}}
\def\hid#1#2{\onslide<#1>{#2}}


\title{Deriving the Binomial PMF}
\author{David Gerard\\
Most slides borrowed from Linda Collins}
\date[\Sexpr{Sys.Date()}]{\Sexpr{Sys.Date()}}


\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
options(format.R.blank=FALSE)
options(width=60)
options(continue=" ")
options(replace.assign=TRUE)
options(scipen=8, digits=4)
opts_chunk$set(
  dev="pdf",
  fig.align='center',
  fig.width=7,
  fig.height=4,
  fig.pos='H',
  fig.show='asis',
  out.width='0.99\\linewidth',
  par=TRUE,
  tidy=FALSE,
  tidy.opts=list(width.cutoff=50),
  prompt=FALSE,
  comment=NA
)
@

\begin{frame}[fragile]
  \titlepage
\end{frame}

\begin{frame}{Learning Objectives}
\begin{itemize}
\item Bernoulli Random Variables
\item Binomial Random Variables
\end{itemize}
\end{frame}

\begin{frame}{A formula}
\begin{itemize}
\item Sometimes, if you are lucky, the pmf may be written as an equation in terms of the value of the random variable.
\item For the coin flipping example, we will derive this formula.
\item Useful beyond just coins: What is the probabiliy of having 3 girls out of 4 children? I.e. many random variables \emph{follow the same distribution}.
\end{itemize}
\end{frame}


%-------------------------------------------------------
%-------------------------------------------------------
\begin{frame}[allowframebreaks]{Using counting rules to determine probabilities}
\vspace{0.5cm}

Since outcomes in the random flip are equally likely,
we just counted the outcomes to determine event probabilities.
\vskip0.5cm

Let's generalize the counting process for this probability model.
\vskip0.5cm

We want a formula for the number of outcomes \\
having $k$ heads out of $4$ flips.
\vskip0.5cm

We begin with a discussion of \\
\textbf{permutations} and\\
\textbf{combinations}
\dots also called \textbf{binomial coefficients}
\end{frame}

\begin{frame}{Permutations}

\textbf{Permutations:} \\~\\
How many ways to order a group of 4 people?
\begin{equation*}
4 \text{ choices for $1$st person } \times (3 \text{ for $2$nd }) \times (2 \text{ for $3$rd }) \times (1 \text{ for $4$th.})
\end{equation*}
How many ways to order a group of $n$ people?
\begin{equation*}
n \times (n-1) \times (n-2) \times \dots \times 2 \times 1 =n!
\end{equation*}
(Note: $n!$ is pronounced ``n factorial.'')
\end{frame}


\begin{frame}{Combinations}

\textbf{Combinations}, also called \textbf{Binomial Coefficients:}
\vskip0.2cm
(Let $n=5$ for the moment just for this one-slide example.)
\vskip0.2cm
How many ways to choose a committee of 2 from a group of 5?
\begin{align*}
& \frac{5 \text{ choices for 1st committee member } \times 4 \text{ for 2nd }}{2! \text{ orderings of $2$ person committee}} \\
&=
\frac{5 \cdot 4 \cdot (3 \cdot 2 \cdot 1)}{2!\; (3 \cdot 2 \cdot 1)}
= \frac{5!}{2!\; 3!}
\end{align*}
How many ways to choose a committee of $k$ from a group of $n$?
\begin{equation*}
{n \choose k} = \frac{n!}{k!\; (n-k)!}
\end{equation*}
Note: ${n \choose k}$ is pronounced ``$n$ choose $k$.''

\end{frame}

\begin{frame}{Counting outcomes}
\textbf{Counting outcomes} for 4 flips of a coin:
\vskip0.4cm

How many outcomes with $2$ heads out of $4$ flips?
\vskip0.4cm

Each sequence has four flips:
$\{\text{First}, \text{Second}, \text{Third}, \text{Fourth}\}$.
\vskip0.4cm

How many outcomes have two heads
\vskip0.2cm

That is, now many ways can we choose two locations from four:
$\{\text{First}, \text{Second}, \text{Third}, \text{Fourth}\}$?
\vskip0.6cm

There are $\displaystyle {n \choose k} = {4 \choose 2}$ ways!

\end{frame}

\begin{frame}{Verify}
\begin{itemize}
\item We can verify this directly\medskip
\item HHTT, HTHT, HTTH, THHT, THTH, TTHH\medskip
\item But this formula always works without having to directly count outcomes.
\end{itemize}
\end{frame}

\begin{frame}{pmf}
How many outcomes total?
\begin{equation*}
2 \text{ choices for $1$st } \times (2 \text{ for $2$nd }) \times (2 \text{ for $3$rd }) \times (2 \text{ for $4$th }) = 2^4 = 16.
\end{equation*}

\textbf{Probability mass function for $X$:}
\begin{equation*}
f(x) = \mathbf{P}(X=x) = \frac{\# \text{outcomes w/ $x$ heads}}{\# \text{outcomes in total}} = \frac{\displaystyle{{4 \choose x}}}{\displaystyle{2^4}}.
\end{equation*}
\end{frame}

%-------------------------------------------------------
%-------------------------------------------------------
\begin{frame}{Using counting rules to determine probabilities}
So, the number of outcomes satisfying $X=2$ is

\begin{flalign*}
\frac{4!}{2!\; 2!}
&= \frac{4!}{2!\; (4-2)!}
= {4 \choose 2}
= \mbox{ ``4 choose 2"} & \\
& = 6 \\
& = \text{the number of ways to arrange 2 heads among 4 flips}
\end{flalign*}
\vspace{-0.5cm}
\begin{align*}
S=\big\{
&HHHH,\\
&HHHT,HHTH,HTHH,THHH,\\
&HHTT,HTHT,HTTH,THTH,TTHH,THHT,\\
&HTTT, THTT,TTHT,TTTH,\\
&TTTT
\big\}.
\end{align*}

\end{frame}
%-------------------------------------------------------
\begin{frame}{Using counting rules to determine probabilities}
\vspace{0.5cm}

The number of ways to arrange $x$ heads among $4$ flips is
$\displaystyle{{4 \choose x}}$.
\vskip1.0cm

How many outcomes have 3 Heads?
\vskip0.35cm

\pause$\displaystyle{{4 \choose 3}=\frac{4!}{3!\;(4-3)!}=\frac{24}{6(1)}=4}$.
\end{frame}
%-------------------------------------------------------
\begin{frame}{Using counting rules to determine probabilities}
\vspace{0.1cm}
Note that in real life, it's not quite true that the probability of having a boy $P(M)$ is equal to the probability of having a girl $P(F)$.

If $P(M)\ne P(F)$,
\vskip0.1cm
are all 4 outcomes with 3 females equally likely?
\vskip0.3cm


\quad ($FFFM, FFMF, FMFF, MFFF$)
\vskip1.2cm

What is $P(FMFF)$?
\end{frame}
%-------------------------------------------------------
\begin{frame}{Using counting rules to determine probabilities}
\vspace{0.1cm}

What is $P(FMFF)$?
\begin{align*}
P(FMFF) &= P(MFF\;|\;F)\times P(F) \\
& \hid{2-}{ = P(MFF)\times P(F)\hskip3.4cm (*) }\\
& \hid{3-}{ = [P(FF\;|\;M)\times P(M)]\times P(F)} \\
& \hid{4-}{ = P(FF)\times P(M) \times P(F)\hskip2.3cm (*)}\\
& \hid{5-}{ = [P(F\;|\;F)\times P(F)]\times P(M)\times P(F)}\\
& \hid{6-}{ = P(F)\times P(F)\times P(M)\times P(F)\hskip1.2cm (*)}\\
& \hid{7-}{ = P(F)^3\times P(M) }
\end{align*}
\hid{2-}{$(*)$ by independence of gender by birth order}
\vskip0.25cm

\hid{8-}{Finally, $\displaystyle{P(X=3)={4 \choose 3}\;P(F)^3\; P(M)}$}

\end{frame}
%-------------------------------------------------------
\begin{frame}{Using counting rules to determine probabilities}
\vspace{0.5cm}

So, even if genders are not equally likely,

we can find probabilities for $X = 0, 1, 2, 3,$ and 4.\\
\vskip1.0cm
First, let $p=P(F)$\hskip1cm ($0<p<1$)
\vskip0.4cm
then $P(M)=1-p$,
\vskip0.4cm
where $0 \le p \le 1$ is the probability of ``success"
(female birth).

\end{frame}
%-------------------------------------------------------
\begin{frame}{Using counting rules to determine probabilities}
\begin{align*}
P(X=3)&={4 \choose 3}\;P(F)^3\; P(M)^{1} \\
 &={4 \choose 3}\;p^3\; (1-p)^{4-3}=6\;p^3\;(1-p)\\[+0.2cm]
P(X=0)&=\hid{2-}{{4 \choose 0}\;p^0\; (1-p)^{4-0}=(1-p)^4}\\[+0.2cm]
P(X=1)&=\hid{3-}{{4 \choose 1}\;p^1\; (1-p)^{4-1}=4\;p\;(1-p)^3}\\[+0.2cm]
P(X=2)&=\hid{4-}{{4 \choose 2}\;p^2\; (1-p)^{4-2}=4\;p^2\;(1-p)^2}\\[+0.2cm]
P(X=4)&=\hid{5-}{{4 \choose 4}\;p^4\; (1-p)^{4-4}=p^4}
\end{align*}

\end{frame}
%-------------------------------------------------------
\begin{frame}{Using counting rules to determine probabilities}
\vspace{0.1cm}

Does this agree with our earlier work when $P(F)=p(M)=0.5$?
\vskip0.3cm

Then, $p=0.5$ and $(1-p)=0.5$.
\begin{align*}
P(X=0)&= (1-p)^4 &= (0.5)^4 &= 1/16\\
P(X=1)&= 4\;p\;(1-p)^3 &= 4\;(0.5)\;(0.5)^3 &= 4/16\\
P(X=2)&= 4\;p^2\;(1-p)^2 &= 6\;(0.5)^2\;(0.5)^2 &= 6/16\\
P(X=3)&= 6\;p^3\;(1-p) &= 4\;(0.5)^3\;(0.5) &= 4/16\\
P(X=4)&= p^4 &= (0.5)^4 &= 1/16
\end{align*}
\vskip0.5cm
Same probability distribution as before!\hskip1cm
That's comforting.

\end{frame}
%-------------------------------------------------------
\begin{frame}{Bernoulli and binomial probability distributions}
A Bernoulli random variable models a very simple process.\\
For example, $Y=$ the number of females in one birth. Then,
\vskip0.2cm

$Y = \begin{cases}
     1 & \text{if child is female}\\
     0 & \text{if child is male}
  \end{cases}$
\vskip0.2cm

where $P(Y=1)=P(F)=p,$ and $P(Y=0)=P(M)=1-p.$
\vskip0.4cm

%The range of $Y$ is just $\{0,1\}.$
%\vskip0.3cm
We say that $Y\sim$ Bernoulli($p$), \\
or $Y$ is a Bernoulli random variable with ``success" probability $p$.

\end{frame}
%-------------------------------------------------------
\begin{frame}{Bernoulli and binomial probability distributions}
Let $Y=$ \# of ``successes" in one Bernoulli ($p$) ``trial"

Then $Y\sim$ Bernoulli($p$) and the pmf for $Y$ is
$$f(y) = \hid{2-}{p^y\;(1-p)^{1-y}\qquad \mbox{for } y=0,1}$$
\vskip0.5cm

Let $X=$ \# of ``successes" in $n$ independent Bernoulli ($p$) ``trials"
\vskip0.2cm

Then, we say that
$X\sim$ binom($n,p$), \\
or $X$ is a binomial random variable with $n$ \textbf{independent} trials and success probability $p$
and the pmf for $X$ is
$$f(x) = \hid{3-}{{n\choose x}\; p^x\;(1-p)^{n-x}\qquad \mbox{for } x=0,1,...,n}$$

\end{frame}
%----------------------------------
  \begin{frame}{The Binomial Expansion}
The coefficients in the expansion match those in Pascal's Triangle:
\begin{align*}
(w+y)^1&=1w^1+~1y^1\\
(w+y)^2&=1w^2+2wy+~~1y^2\\
(w+y)^3&=1w^3+3w^2y+~3w^1y^2+~1y^3\\
(w+y)^4&=1w^4+4w^3y+~6w^2y^2+4wy^3+1y^4\\
(w+y)^5&=1w^5+5w^4y+10w^3y^2+10w^2y^3+5wy^4+1y^5
\end{align*}
\tabcolsep=0pt
\begin{tabular}{ccccccccccc}
&&&&&${0\choose 0}$ &   &   &   &   &\\[-2pt]
 &&&&${1\choose 0}$ && ${1\choose 1}$ &   &   &   &\\[-2pt]
  &&&${2\choose 0}$ && ${2\choose 1}$ && ${2\choose 2}$ &&&\\[-2pt]
   &&${3\choose 0}$ && ${3\choose 1}$ && ${3\choose 2}$ && ${3\choose 3}$ &&\\[-2pt]
    &${4\choose 0}$ && ${4\choose 1}$ && ${4\choose 2}$ && ${4\choose 3}$ && ${4\choose 0}$&\\[-2pt]
     ${5\choose 0}$ && ${5\choose 1}$ && ${5\choose 2}$ && ${5\choose 3}$ && ${5\choose 4}$&&${5\choose 5}$\\[-2pt]
&&&&&$\vdots$
\end{tabular}
$=$
\tabcolsep=2pt
\begin{tabular}{ccccccccccc}
  &   &   &   &   & 1 &   &   &   &   &\\[-2pt]
  &   &   &   & 1 &   & 1 &   &   &   &\\[-2pt]
  &   &   & 1 &   & 2 &   & 1 &   &   &\\[-2pt]
  &   & 1 &   & 3 &   & 3 &   & 1 &   &\\[-2pt]
  & 1 &   & 4 &   & 6 &   & 4 &   & 1 &\\[-2pt]
1 &   & 5 &   & 10&   & 10&   & 5 &   & 1\\[-2pt]
&&&&&$\vdots$
\end{tabular}
\end{frame}
%----------------------------------

\begin{frame}{The Binomial Expansion}

In general,\\
$\displaystyle{
(w+y)^n =
\underbrace{(w+y)(w+y)\ldots(w+y)}_{n\mbox{\small\ factors}}=\sum_{x=0}^n {n\choose x} w^x y^{n-x}
}$
\vskip0.3cm

General idea:\\
$\displaystyle{
w^5 y^3 =  w w w w w y y y = w w w w y w y y = \cdots = y y y w w w w w
}$
\vskip0.3cm
\pause

This result guarantees that the binomial RV has a valid pmf.
\vskip0.3cm
To see this, let $w=p, y=(1-p).$  Then,
$\displaystyle{\sum_{x=0}^n {n\choose x} p^x (1-p)^{n-x}}$
$\displaystyle{
=\sum_{x=0}^n {n\choose x} w^x y^{n-x}
= (w+y)^n = (p + (1-p))^n = 1^n = 1
}$
\vskip0.3cm

The probabilities for any valid pmf must sum to 1.

\end{frame}
%-------------------------------------------------------
\begin{frame}{Multiple Random Variables, Same Sample Space}

We can define several random variables on this same experiment (the same
sample space):
\begin{align*}
X &= \text{Number of female children}\\
Y &= \text{Number of male children before the first female child is born}\\
Z &= \begin{cases}
     1 & \text{if more female children than male}\\
     0 & \text{otherwise}
     \end{cases}
\end{align*}

{\scriptsize
\begin{center}
\begin{tabular}{c|ccc|c|ccc|c|ccc}
    Outcome & $X$ & $Y$ & $Z$
  & Outcome & $X$ & $Y$ & $Z$
  & Outcome & $X$ & $Y$ & $Z$ \\
\hline
FFFF & 4 & 0 & 1 & FFMM & 2 & 0 & 0 & FMMM & 1 & 0 & 0 \\
     &   &   &   & FMFM & 2 & 0 & 0 & MFMM & 1 & 1 & 0 \\
FFFM & 3 & 0 & 1 & FMMF & 2 & 0 & 0 & MMFM & 1 & 2 & 0 \\
FFMF & 3 & 0 & 1 & MFMF & 2 & 1 & 0 & MMMF & 1 & 3 & 0 \\
FMFF & 3 & 0 & 1 & MFFM & 2 & 1 & 0 &      &   &   &   \\
MFFF & 3 & 1 & 1 & MMFF & 2 & 2 & 0 & MMMM & 0 & 4 & 0 \\
\end{tabular}
\end{center}
}

\end{frame}
%-------------------------------------------------------
\begin{frame}{Multiple pmfs, Same Sample Space}

We can define several random variables and their corresponding
pmfs on this same experiment (the same sample space):
{\scriptsize
\begin{center}
\begin{tabular}{c|ccc|c|ccc|c|ccc}
    Outcome & $X$ & $Y$ & $Z$
  & Outcome & $X$ & $Y$ & $Z$
  & Outcome & $X$ & $Y$ & $Z$ \\
\hline
FFFF & 4 & 0 & 1 & FFMM & 2 & 0 & 0 & FMMM & 1 & 0 & 0 \\
     &   &   &   & FMFM & 2 & 0 & 0 & MFMM & 1 & 1 & 0 \\
FFFM & 3 & 0 & 1 & FMMF & 2 & 0 & 0 & MMFM & 1 & 2 & 0 \\
FFMF & 3 & 0 & 1 & MFMF & 2 & 1 & 0 & MMMF & 1 & 3 & 0 \\
FMFF & 3 & 0 & 1 & MFFM & 2 & 1 & 0 &      &   &   &   \\
MFFF & 3 & 1 & 1 & MMFF & 2 & 2 & 0 & MMMM & 0 & 4 & 0 \\
\end{tabular}
\end{center}
}

{\small
\begin{tabular}{r|ccccc}
$x$ & 0&1&2&3&4\\
\hline
$f(x)$ & 1/16&4/16&6/16&4/16&1/16\\
\end{tabular}
\vskip0.25cm

\begin{tabular}{r|ccccc}
$y$ &
\hid{2-}{0}&\hid{3-}{1}&\hid{4-}{2}&\hid{4-}{3}&\hid{4-}{4}\\
\hline
$f(y)$ &
\hid{2-}{8/16}&\hid{3-}{4/16}&\hid{4-}{2/16}&\hid{4-}{1/16}&\hid{4-}{1/16}\\
\end{tabular}
\vskip0.25cm

\begin{tabular}{r|cc}
$z$ & \hid{5-}{0}&\hid{6-}{1}\\
\hline
$f(z)$ & \hid{5-}{11/16}&\hid{6-}{5/16}\\
\end{tabular}
}
\end{frame}
%-------------------------------------------------------
\begin{frame}{Probability Histograms}

\begin{tabular}{r|ccccc}
$x$ & 0&1&2&3&4\\
\hline
$f(x)$ & 1/16&4/16&6/16&4/16&1/16\\
\end{tabular}
\vskip0.2cm

\begin{tabular}{r|ccccc}
$y$ & 0&1&2&3&4\\
\hline
$f(y)$ & 8/16&4/16&2/16&1/16&1/16\\
\end{tabular}
\vskip0.2cm

\begin{tabular}{r|cc}
$z$ & 0&1\\
\hline
$f(z)$ & 11/16&5/16\\
\end{tabular}
\vskip-0.2cm

<<echo=FALSE, fig.height=3.0>>=
par(mfrow=c(1,3), oma=c(0,0,0,0)+0.01, mar=c(4,4,1,1)+0.01, cex=1.20)
x <- 0:4;  fx <- c(1,4,6,4,1)/16
names(fx) <- as.character(x)
barplot(fx, space=0, col="grey", xlab="x", ylab="f(x)=probability", ylim=c(0,11/16))
y <- 0:4;   fy <- c(8,4,2,1,1) / 16
names(fy) <- as.character(y)
barplot(fy, space=0, col="grey", xlab="y", ylab="f(y)=probability", ylim=c(0,11/16))
z <- 0:4;   fz <- c(11,5,0,0,0) / 16
names(fz) <- as.character(z)
barplot(fz, space=0, col="grey", xlab="z", ylab="f(z)=probability", ylim=c(0,11/16))
@

%\includegraphics[width=10cm]{ProbHistograms}

\end{frame}
%-------------------------------------------------
% \begin{frame}{Expected Value (Mean)}
%
% What is the average value for each random variable?
% \begin{align*}
% \mbox{Mean of\ } X &= \mu = ``\mbox{myoo}"\\
% &= \mbox{Expected value of\ } X = E(X)\\
% &= \mbox{Balancing point of the probability distribution of\ } X
% \end{align*}
% What is the expected value of $X?$
% %\begin{tabular}{r|ccccc}
% %$x$ & 0&1&2&3&4\\
% %\hline
% %$f(x)$ & 1/16&4/16&6/16&4/16&1/16\\
% %\end{tabular}
%
% <<echo=FALSE, fig.height=2.0>>=
% par(mfrow=c(1,1), oma=c(0,0,0,0)+0.01, mar=c(4,4,1,1)+0.01, cex=1.20)
% x <- 0:4;  fx <- c(1,4,6,4,1)/16
% names(fx) <- as.character(x)
% barplot(fx, space=0, col="grey", xlab="x", ylab="f(x)=probability", ylim=c(0,11/16))
% @
% \vskip-0.3cm
% $E(X) = \hid{2-}{2 \;\;\mbox{\ (by symmetry)}}$\qquad
% \hid{3-}{But $Y$ and $Z$ distns not symmetric.}
% \end{frame}
% %%%%%%%%%%%%%%%%
% \begin{frame}{Expected Value (Mean of a r.v.)}
%
%
% {\bf Developing a general formula for expected value:}\\
% Suppose that 16, 4-child families are chosen at random.\\
% \medskip
% We would ``expect" to observe about\\
% 1 family with all girls $(FFFF)$,\\
% 4 families with 3 girls $(FFFM, FFMF, FMFF, MFFF)$,\\
% 6 families with 2 girls,\\
% 4 families with 1 girl, and\\
% 1 family with 0 girls.
% \begin{align*}
% & \mbox{Average (in the ``long run" using counting theory)}\\
% & =\frac{\mbox{total \# of girls}}{\mbox{total \# of families}}\\
% &= \frac{4+3+3+3+3+2+2+2+2+2+2+1+1+1+1+0}{16}\\
% &= 32/16 = 2
% \end{align*}
%
% \end{frame}
% %%%%%%%%%%%%%%%%
% \begin{frame}{Expected Value (Mean of a r.v.)}
%
% Then, average number of girls per family (mean of $X$)\\
% can be rewritten...
% \begin{align*}
% & \mbox{Average}\\
% &= \frac{4 (1 \mbox{\ family}) + 3(4 \mbox{\ families}) + 2(6 \mbox{\ fam})
%          + 1(4 \mbox{\ fam}) + 0(1 \mbox{\ fam})}{16}\\
% &= 4\times\frac{1}{16} + 3\times\frac{4}{16} + 2\times\frac{6}{16}
%    + 1\times\frac{4}{16} + 0\times\frac{1}{16}\\
% &= \sum_{x=0}^4 x\; P(X=x)\\
% &= \sum_{x=0}^4 x\; f(x)
% \end{align*}
%
% \end{frame}
% %%%%%%%%%%%%%%%%
% \begin{frame}{Expected Value (Mean of a r.v.)}
% \vspace{0.1cm}
%
% {\bf Definition of Expected Value:}
% \begin{align*}
% E(X) &= \text{weighted average of all possible outcomes $x$}\\\\
% E(X) &= \sum_{\text{all\ } x}\; x\; P(X=x)\\[+0.3cm]
% &= \sum_x\; x\; f(x)\\[+0.3cm]
% &= \mu
% \end{align*}
%
% This is a long-run average, the average of a random variable,\\
% and the average for the probability model of the population (or process)
% distribution from which the data come.
%
% \end{frame}
%%%%%%%%%%%%%%%%

\begin{frame}{Recall: Mean}
\begin{block}{Mean (Expected Value)}
Suppose $X$ is a discrete random variable, then
\begin{align*}
  \text{\alert{mean} of } X &= E[X] \\
  &= \sum_{\text{all } x}xP(X = x)\\
  &=\sum_{\text{all } x}xf(x)\\
  &=\mu
\end{align*}
\end{block}
\end{frame}

\begin{frame}{Expected Value (Mean of a r.v.)}

Find  expected value (mean) of random variable $Y$.


$Y =$ \# of male children before the first female child is born

\begin{tabular}{r|ccccc}
$y$ &
0&1&2&3&4\\
\hline
$f(y)$ &
8/16&4/16&2/16&1/16&1/16\\
\end{tabular}
<<echo=FALSE, fig.height=3.0>>=
par(mfrow=c(1,1), oma=c(0,0,0,0)+0.01, mar=c(4,4,1,1)+0.01, cex=1.20)
y <- 0:4;   fy <- c(8,4,2,1,1) / 16
names(fy) <- as.character(y)
barplot(fy, space=0, col="grey", xlab="y", ylab="f(y)=probability", ylim=c(0,11/16))
@
\vskip-1.45cm
\begin{align*}
E(Y) &=
\hid{2-}{\sum_{y=0}^4 y f(y)}\\
&= \hid{2-}{(0)8/16 + (1)4/16 + (2)2/16 + (3)1/16 + (4)1/1 = 15/16}
\end{align*}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Expected Value (Mean of a r.v.)}

The random variable $Z$ is a Bernoulli r.v.
%\quad{\tiny Top Hat: $E(Z)$}
$Z = \begin{cases}
    1 & \text{if more female children than male}\\
    0 & \text{otherwise}
    \end{cases}$

\begin{tabular}{r|cc}
$z$ & 0&1\\
\hline
$f(z)$ & 11/16&5/16\\
\end{tabular}
<<echo=FALSE, fig.height=2>>=
par(mfrow=c(1,1), oma=c(0,0,0,0)+0.01, mar=c(4,4,1,1)+0.01, cex=1.20)
z <- 0:4;   fz <- c(11,5,0,0,0) / 16
names(fz) <- as.character(z)
barplot(fz, space=0, col="grey", xlab="z", ylab="f(z)=probability", ylim=c(0,11/16))
@
\vskip-0.5cm
Make a guess.  Approximate the average outcome for $Z$.\\
$E(Z) = $
\hid{2-}{$\displaystyle{\sum_{z=0}^1 z f(z) = (0)11/16 + (1)5/16 = 5/16.}$}

\end{frame}
%%%%%%%%%%%%%%%%
\begin{frame}{Expected Value of a Bernoulli Random Variable}
\vspace{0.2cm}

The random variable $Z$ is a Bernoulli r.v.
\vskip0.2cm
$Z = \begin{cases}
    1 & \text{if more female children than male = ``success"}\\
    0 & \text{otherwise = ``failure"}
    \end{cases}$

Probability mass function (PMF):\hskip1.5cm
\begin{tabular}{r|cc}
$z$ & 0&1\\
\hline
$f(z)$ & $(1-p)$ & $p$\\
\end{tabular}
where $p=5/16$ = probability of a success.

\begin{align*}
\mu_Z = E(Z) &= \text{weighted average of all possible outcomes $x$}\\[+0.3cm]
E(Z) &= \sum_{\text{all\ } z}\; z\; P(Z=z)
= \sum_{z=0,1}\; z\; P(Z=z)\\[+0.1cm]
&= (0)(1-p) + (1)(p) = p = 5/16.
\end{align*}

\end{frame}
%%%%%%%%%%%%%%%%
\begin{frame}{Expected Value of a Bernoulli Random Variable}
\vspace{0.2cm}

The random variable $Z$ is a Bernoulli r.v.
\vskip0.2cm
$Z = \begin{cases}
    1 & \text{if more female children than male = ``success"}\\
    0 & \text{otherwise = ``failure"}
    \end{cases}$


Prob mass function (PMF):\hfill
$f(z) = p^z\;(1-p)^{1-z}\quad \mbox{for } z=0,1$

where $p=5/16$ = probability of a success.

\begin{align*}
\mu_Z = E(Z) &= \text{weighted average of all possible outcomes $x$}\\[+0.3cm]
E(Z) &= \sum_{\text{all\ } z}\; z\; f_Z(z)
= \sum_{z=0}^1\; z\; p^z\;(1-p)^{1-z}\\[+0.1cm]
&= (0)p^0(1-p)^{1-0} + (1)p^1(1-p)^{1-1} = p = 5/16.
\end{align*}

\end{frame}
%%%%%%%%%%%%%%%%
\begin{frame}{The Binomial Setting}
\vspace{0.2cm}

\begin{enumerate}[1.]
\item
There is a fixed number of observations $n$.
\item
The $n$ observations are all independent.
\item
Each observation falls into one of just two categories.

For convenience, called ``success" and ``failure"
\item
The probability of a success ($p$) \\
is the same for each observation.
\end{enumerate}

\end{frame}
%%%%%%%%%%%%%%%%
\begin{frame}{The Binomial Distribution}
\vspace{0.2cm}

Let $X$ = the count of successes in a Binomial setting
\vskip0.5cm

Then, the following statements are equivalent:
\begin{itemize}
\item
$X$ has a Binomial distribution with parameters $n$ and $p$.
\item
$X$ is a Binomial($n,p$) random variable.
\item
$X\sim$ Binomial($n,p$).
\item
$X$ is the sum of $n$ independent Bernoulli r.v. (***)
\item
The probability mass function (pmf) for random variable $X$ is
$$f(x) = {n\choose x}\; p^x\;(1-p)^{n-x}\qquad \mbox{for } x=0,1,...,n$$
\end{itemize}

$n=$ number of observations (sample size)

$p=$ probability of success for any one observation


\end{frame}
%%%%%%%%%%%%%%%%
\begin{frame}{Expected Value of a Binomial Random Variable}
\vspace{0.2cm}

Is $X$ a Binomial($n,p$) random variable?
\vskip0.5cm

Without studying, you plan to
randomly guess each quiz question.
\begin{enumerate}[(1)]
\item
$X = $ number of correct answers in a quiz with 10 questions
and 5 choices per question (A, B, C, D, E).
\item
$X = $ number of correct answers in a quiz with 100 questions
and 4 choices per question (A, B, C, D).
\item
$X = $ number of correct answers in a quiz with 50 questions
and 4 choices per question (A, B, C, D).
\end{enumerate}
In each case, how many correct answers do you expect to get?

\vskip0.5cm
Let $X=$ \# of ``successes" in $n$ independent Bernoulli ($p$) ``trials"

Is $X$ Binomial($n,p$)?\hskip1cm
What is $E(X)$?


\end{frame}
%%%%%%%%%%%%%%%%
\begin{frame}{Expected Value of a Binomial Random Variable}
\vspace{0.2cm}

\begin{block}{Mean of Binomial RV}
If $X$ is a Binomial($n,p$) random variable, $E(X)=np$.
\end{block}

\begin{align*}
E(X) &= \sum_{\text{all } x}\; x\; f(x)\\
&= \sum_{x=0}^n\;\; x\;\;{n\choose x}\; p^x\;(1-p)^{n-x}\\
&= np
\end{align*}

We'll learn an easy way to prove this.

\end{frame}

\end{document}
