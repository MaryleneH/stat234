\documentclass{beamer}
\usepackage{amsmath,algorithm,algorithmic,graphicx,amsfonts,amsthm,color,pgf,tikz,wrapfig,amsfonts,multicol,wasysym,animate, appendixnumberbeamer}
\usepackage[misc]{ifsym}
\beamertemplatenavigationsymbolsempty
\useoutertheme[subsection=false]{miniframes}
\usetheme[progressbar=frametitle]{metropolis}
\metroset{block=fill}

\providecommand{\code}[1]{}
\renewcommand{\code}[1]{{\color{blue!80!black}\texttt{#1}}}

\newfont\dice{dice3d}
%\DeclareFontShape{U}{dice3d}{m}{n}{<-> s*[4] dice3d}{}

\title{Introduction to Probability}
\author{David Gerard\\
Some slides are borrowed from Linda Collins}
\date[\Sexpr{Sys.Date()}]{\Sexpr{Sys.Date()}}


\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
options(format.R.blank=FALSE)
options(width=60)
options(continue=" ")
options(replace.assign=TRUE)
options(scipen=8, digits=4)
opts_chunk$set(
  dev="pdf",
  fig.align='center',
  fig.width=7,
  fig.height=4,
  fig.pos='H',
  fig.show='asis',
  out.width='0.99\\linewidth',
  par=TRUE,
  tidy=FALSE,
  tidy.opts=list(width.cutoff=50),
  prompt=FALSE,
  comment=NA
)
@

\begin{frame}[fragile]
  \titlepage
\end{frame}

\begin{frame}{Learning Objective}
\begin{itemize}
\item Sample Space/Events
\item Axioms of Probability
\item Some Probability Rules
\item Sections 2.1.1 to 2.1.5 in DBC
\end{itemize}
\end{frame}

\begin{frame}{Recall: Sample vs Population}
\begin{block}{population}
A \alert{population} is a group of cases for which you want information.
\end{block}
\begin{block}{sample}
A \alert{sample} is a subgroup of cases of the population.
\end{block}
A \alert{simple random sample} is when we choose a subset of the population where each subset is equally likely to be chosen.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Probability vs. Statistics}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
\item {\bf Statistics (Inference):}
\begin{itemize}
\item Just observe a sample. What can we conclude (probabilistically) about the population?
\item Sample $\longrightarrow$ Population?
\item Messy and more of an art.
\item No correct answers. Lots of wrong answers. Some ``good enough'' answers.
\end{itemize}
\item {\bf Probability (from the viewpoint of Statisticians):}
\begin{itemize}
\item Logically self-contained, a subset of Mathematics.
\item One correct answer.
\item We know the population. What is the probability of the sample?
\item Population $\longrightarrow$ Sample?
\end{itemize}
\end{itemize}

\end{frame}

\begin{frame}{What is Probability?}
\begin{block}{Random}
We call a phenomenon \alert{random} if individual outcomes are uncertain but there is, nonetheless, a regular distribution of outcomes in a large number of repetitions.
\end{block}
\begin{block}{Probability}
The \alert{probability} of any outcome of a random phenomenon is the proportion of times the outcome would occur in a very long series of repetitions.
\end{block}
\end{frame}

\begin{frame}[fragile]{Flipping a coin}
The probability of a fair coin landing heads is 0.5 because, in the long run, half of the time the coin will land heads.
<<echo=FALSE>>=
set.seed(1)
x <- sample(c(0, 1), size = 1, prob = c(1/2, 1/2))
plot(1, x, xlim = c(0, 50), ylim = c(0, 1),
     xlab = "Proportion Heads", ylab = "Trial Number",
     main = "One flip")
abline(h = 0.5, col = 2, lwd = 2, lty = 2)
@
\end{frame}

\begin{frame}[fragile]{Flipping a coin}
<<echo=FALSE>>=
x <- c(x, sample(c(0, 1), size = 1, prob = c(1/2, 1/2)))
y <- cumsum(x) / (1:length(x))
plot(c(1:length(x)), y, xlim = c(0, 50), ylim = c(0, 1),
     xlab = "Proportion Heads", ylab = "Trial Number", type = "l",
     main = "Two flips")
points(length(x), y[length(x)])
abline(h = 0.5, col = 2, lwd = 2, lty = 2)
@
\end{frame}

\begin{frame}[fragile]{Flipping a coin}
<<echo=FALSE>>=
x <- c(x, sample(c(0, 1), size = 1, prob = c(1/2, 1/2)))
y <- cumsum(x) / (1:length(x))
plot(c(1:length(x)), y, xlim = c(0, 50), ylim = c(0, 1),
     xlab = "Proportion Heads", ylab = "Trial Number", type = "l",
     main = "Three flips")
points(length(x), y[length(x)])
abline(h = 0.5, col = 2, lwd = 2, lty = 2)
@
\end{frame}

\begin{frame}[fragile]{Flipping a coin}
<<echo=FALSE>>=
x <- c(x, sample(c(0, 1), size = 1, prob = c(1/2, 1/2)))
y <- cumsum(x) / (1:length(x))
plot(c(1:length(x)), y, xlim = c(0, 50), ylim = c(0, 1),
     xlab = "Proportion Heads", ylab = "Trial Number", type = "l",
     main = "Four flips")
points(length(x), y[length(x)])
abline(h = 0.5, col = 2, lwd = 2, lty = 2)
@
\end{frame}

\begin{frame}[fragile]{Flipping a coin}
<<echo=FALSE>>=
x <- c(x, sample(c(0, 1), size = 1, prob = c(1/2, 1/2)))
y <- cumsum(x) / (1:length(x))
plot(c(1:length(x)), y, xlim = c(0, 50), ylim = c(0, 1),
     xlab = "Proportion Heads", ylab = "Trial Number", type = "l",
     main = "Five flips")
points(length(x), y[length(x)])
abline(h = 0.5, col = 2, lwd = 2, lty = 2)
@
\end{frame}

\begin{frame}[fragile]{Flipping a coin}
<<echo=FALSE>>=
x <- c(x, sample(c(0, 1), size = 5, prob = c(1/2, 1/2), replace = TRUE))
y <- cumsum(x) / (1:length(x))
plot(c(1:length(x)), y, xlim = c(0, 50), ylim = c(0, 1),
     xlab = "Proportion Heads", ylab = "Trial Number", type = "l",
     main = "10 flips")
points(length(x), y[length(x)])
abline(h = 0.5, col = 2, lwd = 2, lty = 2)
@
\end{frame}

\begin{frame}[fragile]{Flipping a coin}
<<echo=FALSE>>=
x <- c(x, sample(c(0, 1), size = 90, prob = c(1/2, 1/2), replace = TRUE))
y <- cumsum(x) / (1:length(x))
plot(c(1:length(x)), y, xlim = c(0, 100), ylim = c(0, 1),
     xlab = "Proportion Heads", ylab = "Trial Number", type = "l",
     main = "100 flips")
points(length(x), y[length(x)])
abline(h = 0.5, col = 2, lwd = 2, lty = 2)
@
\end{frame}

\begin{frame}[fragile]{Flipping a coin}
<<echo=FALSE>>=
x <- c(x, sample(c(0, 1), size = 900, prob = c(1/2, 1/2), replace = TRUE))
y <- cumsum(x) / (1:length(x))
plot(c(1:length(x)), y, xlim = c(0, 1000), ylim = c(0, 1),
     xlab = "Proportion Heads", ylab = "Trial Number", type = "l",
     main = "1000 flips")
points(length(x), y[length(x)])
abline(h = 0.5, col = 2, lwd = 2, lty = 2)
@
\end{frame}

\begin{frame}{Law of Large Numbers}
This just illustrated a fact known as the
\begin{block}{Law of Large Numbers}
If a situation, trial, or experiment is repeated, the proportion of
outcomes of interest is more and more likely to be close to the
probability of the outcome of interest as we repeat the experiment
more and more times.
\end{block}
\end{frame}


\begin{frame}{Sample Spaces and Events}
\begin{block}{Sample Space}
The \alert{sample space $S$} of a random phenomenon is the set of all possible outcomes.
\end{block}
\begin{block}{Event}
An \alert{event} is an outcome or a set of outcomes of a random phenomenon. That is, an event is a subset of the sample space. We will denote the set of all events by $\mathcal{A}$.
\end{block}

E.g.: Suppose you roll a fair six-sided die once, what is the sample space?\\
Answer: %$S = \{1,2,3,4,5,6\}$

E.g.: What are all possible events?\\
Answer: %all possible subsets of $S$, e.g. $\{1\}$, $\{2,5\}$, $\{1,2,3,4,5,6\}$, etc...
\end{frame}

\begin{frame}{Sample Spaces and Events: Another Example}
Suppose you flip a fair coin twice and observe the sequence of heads and tails, what is the sample space?\\
Answer: $S = \{HH, HT, TH, TT\}$,

What are all possible events?\\
Answer: All subsets of $S$. E.g. $\{HH, HT\}$, $\{HH, TH, TT\}$, etc...

Suppose instead of the sequence, you measure the number of heads. What is the sample space?\\
Answer:

What are the possible events?\\
Answer:

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The Axioms of Probability}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
A {\bf probability} on a sample space $S$ (and a set $\mathcal{A}$
of events) is a function which assigns each event $A$ (in
$\mathcal{A}$) a value in $[0,1]$ and satisfies the following rules:

\begin{itemize}
\item
{\bf Axiom 1:} All probabilities are nonnegative:
\[P(A)\geq 0\qquad\mbox{for all events $A$}.\]
\item
{\bf Axiom 2:} The probability of the whole sample space is 1:
\[P(S)=1.\]
\item
{\bf Axiom 3 (Addition Rule):} If two events $A$ and $B$ are disjoint (have no outcomes in common) then
\[
P(A\cup B)=P(A)+P(B),
\]
%that is the probability that $A$ or $B$ occurs is the sum of their probabilities.

%More general form: If $\{A_1, A_2, A_3, \ldots\}$ is a sequence of
%mutually exclusive events, then
%\vspace{-7pt}
%\[
%P(A_1\cup A_2\cup A_3\cup\ldots) = \sum_{i=1}^{\infty} P(A_i)
%\]
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{The Axioms of Probablity: Example of Application}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Suppose a random experiment has $N$ different outcomes,
such that $i$th outcomes occurs with probability $p_i$, $i=1,\ldots,N$.
It is natural to define the probability of an event as the sum of the probabilities of
the distinct outcomes making up the event.\par

\textbf{Why do we need to learn techniques for counting?}
If each outcome  equally likely,  $p_1=\ldots=p_N=1/N$,
then for any event $A$,
\[ P(A) = \frac{\#(A)}{\#(S)}=\frac{\mbox{number of outcomes in $A$}}
  {\mbox{number of outcomes in $S$}} \]

This setup satisfies the 3 axioms
\begin{columns}[T]
\begin{column}{.35\textwidth}
\begin{itemize}
\item
$P(A)\geq 0$
\item
$\displaystyle P(S)=\frac{\#(S)}{\#(S)}=1$
\end{itemize}
\end{column}
\begin{column}{.64\textwidth}
\begin{itemize}
\item
If $A$ and $B$ are disjoint then
\begin{align*}
P(A\cup B)=\frac{\#(A\cup B)}{\#(S)}
&=\frac{\#(A)}{\#(S)}+\frac{\#(B)}{\#(S)}\\
&=P(A)+P(B).
\end{align*}
\end{itemize}
\end{column}
\end{columns}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{In some cases}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

{\bf Symmetry of outcomes: all outcomes of an experiment are assumed equally likely}

\medskip
Assume $N$ outcomes:
Probability of an outcome: $1/N$.

Event is defined as
a subset of possible outcomes.

Probability of event containing $n$ outcomes: $n/N$\\

\begin{itemize}
\item
requires finitely many and equally likely outcomes
\item
can be determined by counting outcomes
\end{itemize}

E.g.: Roll a six-sided die, then\\
$P(1) = P(2) = P(3) = P(4) = P(5) = P(6) = 1/6$\\

E.g.: Roll a six-sided die twice, then\\
$P(2 \text{ and } 3) = P(1 \text{ and } 1) = P(6 \text{ and } 3) = P(4 \text{ and } 5) = \cdots = 2/6$

\end{frame}

\section{Set Theory Primer}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{A Set Theory Primer}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}
A set is {\em``a collection of definite, well distinguished objects
of our perception or of our thought''}.
{\scshape\normalsize (Georg Cantor, 1845-1918)}
\end{center}
\bigskip

Some important sets:
\begin{itemize}
\item
$\mathbb{N}=\{1,2,3,\ldots\}$, the set of {\em natural numbers}
\item
$\mathbb{Z}=\{\ldots,-2,-1,0,1,2,\ldots\}$, the set of {\em integers}
\item
$\mathbb{R}=(-\infty,\infty)$, the set of {\em real numbers}
\end{itemize}
\vskip0.3cm

Intervals are denoted as follows:
\begin{itemize}
\item[\quad]
$[0,1]$\quad the interval from 0 to 1 including 0 and 1
\item[\quad]
$[0,1)$\quad the interval from 0 to 1 including 0 but not 1
\item[\quad]
$(0,1)$\quad the interval from 0 to 1 not including 0 and 1
\end{itemize}
If $a$ is an element of the set $A$ then we write $a\in A$.
\medskip

If $a$ is not an element of the set $A$ then we write $a\notin A$.

\end{frame}

\begin{frame}{Set's are intuitively thought of in terms of Venn diagrams}
\begin{itemize}
\item $S$ = a set, $A$ = a subset of $S$, $B$ = another subset of $S$.
\item Denoted $A \subseteq S$ and $B \subseteq S$.
\end{itemize}
\begin{center}
\includegraphics[scale = 0.7]{./venn/basic_venn}
\end{center}
\end{frame}

\begin{frame}{Empty Set}
\begin{itemize}
\item The set with no elements is called the \alert{empty set}.
\item Denoted $\emptyset$.
\item For any set $A$, we have $\emptyset \subseteq A$.
\end{itemize}
\end{frame}

\begin{frame}{Set complement}
\begin{itemize}
\item \alert{Set Complement}: Set of all elements in $S$ that are not in $A$.
\item Denoted $A$ ($A^c$ or $A'$)
\end{itemize}
\begin{center}
\includegraphics[scale = 0.7]{./venn/nota}
\end{center}
\end{frame}

\begin{frame}{Intersection}
\begin{itemize}
\item The \alert{intersection} of $A$ and $B$: Set of all elements in $S$ which are both in $A$ and in $B$.
\item Denoted $A \cap B$.
\end{itemize}
\begin{center}
\includegraphics[scale=0.7]{./venn/anb}
\end{center}
\end{frame}

\begin{frame}{Set difference}
\begin{itemize}
\item The \alert{set difference} of $A$ and $B$: Set of all elements in $A$ which are not in $B$.
\item Denoted $A\setminus B = A \cap B^c$.
\end{itemize}
\begin{center}
\includegraphics[scale = 0.7]{./venn/alessb}
\end{center}
\end{frame}

\begin{frame}{Set union}
\begin{itemize}
\item The \alert{union} of $A$ and $B$: Set of all elements in $S$ that are in $A$ or in $B$ or in both.
\item Denoted $A\cup B$.
\end{itemize}
\begin{center}
\includegraphics[scale=0.7]{./venn/aorb}
\end{center}
\end{frame}

\begin{frame}{Two questions}
\begin{itemize}
\item What is $A \cup A^c$?
\item What is $A \cap A^c$?
\end{itemize}
\end{frame}

\begin{frame}{Disjoint/mutually exclusive}
\begin{itemize}
\item $A$ and $B$ are \alert{disjoint} if $A$ and $B$ have no common
elements, that is $A\cap B=\emptyset$.
Two events $A$ and $B$ with this property are said to be \alert{mutually exclusive}.
\end{itemize}
\begin{center}
\includegraphics[scale=0.7]{./venn/disjoint}
\end{center}
\end{frame}


\section{Some rules of probability}

\begin{frame}{Set of all events satisifies}

{\bf We assume the collection of events $\mathcal{A}$ satisfies:}

\begin{itemize}
\item $\phi,S \in \mathcal{A}$
\item if $A \in \mathcal{A}$ then $A^c \in \mathcal{A}$
\item If $A,B \in \mathcal{A}$ then $A \cap B \in \mathcal{A}$
\item If $A,B \in \mathcal{A}$ then $A \cup B \in \mathcal{A}$
\item If $A \in \mathcal{A}$ then $A \cap B \in \mathcal{A}$
\end{itemize}


%\[
%\omega\in A\cup B\follows \omega\in A \text{ or } \omega\in B
%\]
%\[
%\omega\in A^c\follows \omega\notin A
%\]

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Partition Rule}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Let $A$ and $B$ be events in a outcome set $S$.
\medskip

\begin{block}{Partition rule}
$P(A)=P(A\cap B)+P(A\cap B^c)$
\end{block}
\begin{center}
\includegraphics[scale=0.7]{./venn/partition_rule}
\end{center}

\end{frame}

\begin{frame}{Partition Rule}

{\em Example:}
Roll a pair of fair dice
\begin{align*}
P(&\text{Total of 10})\\
&=P(\text{Total of 10 and double})
+P(\text{Total of 10 and no double})\\
&=\frac{1}{36}+\frac{2}{36}=\frac{3}{36}=\frac{1}{12}
\end{align*}
\end{frame}

\begin{frame}{Complement Rule}

\begin{block}{Complement rule:}
$P(A^c)=1-P(A)$
\end{block}

\medskip
{\em Example:}
Often useful for events of the type ``at least one''\\
or ``at least as large as some small number"
%\begin{align*}
%P(&\text{Total is at least 4})\\
%&=1-P(\text{Total is less than 4})
%=1-\frac{3}{36}=\frac{33}{36}
%\end{align*}
\[
P(\text{Total is at least 4})
=1-P(\text{Total is less than 4})
=1-\frac{3}{36}=\frac{33}{36}
\]

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Containment Rule}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Let $A$ and $B$ be events in an outcome set $S$.
\medskip

\begin{block}{Containment rule}
$P(A)\leq P(B)$
for all $A\subseteq B$
\end{block}

{\em Example:} Compare ``two ones" with ``any double",
\[
\frac{1}{36}=P(\text{two ones})\leq
P(\text{any double})=\frac{6}{36}=\frac{1}{6}
\]

\begin{center}
\includegraphics[scale = 0.5]{./venn/containment_rule}
\end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}{Inclusion Exclusion Formula}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{block}{Inclusion exclusion formula}
$P(A\cup B)=P(A)+P(B)-P(A\cap B)$
\end{block}

{\em Example:}
Roll a pair of fair dice
\begin{align*}
P(&\text{Total of 10 or double})\\
&=P(\text{Total of 10})
+P(\text{Double})-P(\text{Total of 10 and double})\\
&=\frac{3}{36}+\frac{6}{36}-\frac{1}{36}=\frac{8}{36}=\frac{2}{9}
\end{align*}
The two events are
$
\text{Total of 10}=\{(4,6),(6,4),(5,5)\}
$
and
\[
\text{Double}
=\{(1,1),(2,2),(3,3),(4,4),(5,5),(6,6)\}
\]
The intersection is
$\displaystyle{
\text{Total of 10 and double}=\{(5,5)\}.}$

Adding the probabilities for the two events, the probability for
the event $\{(5,5)\}$ is added twice, so we need to subtract this
probability back out.

\end{frame}

\begin{frame}{Inclusion Exclusion}

\begin{center}
\includegraphics[scale=0.7]{./venn/inclusion_exclusion}
\end{center}

\end{frame}


\end{document}
