\documentclass{beamer}
\usepackage{amsmath,algorithm,algorithmic,graphicx,amsfonts,amsthm,color,pgf,tikz,wrapfig,amsfonts,multicol,wasysym,animate, appendixnumberbeamer}
\beamertemplatenavigationsymbolsempty
\useoutertheme[subsection=false]{miniframes}
\usetheme[progressbar=frametitle]{metropolis}
\metroset{block=fill}

\providecommand{\code}[1]{}
\renewcommand{\code}[1]{{\color{blue!80!black}\texttt{#1}}}


\title{Densities and the Normal Distribution}
\author{David Gerard}
\date[\Sexpr{Sys.Date()}]{\Sexpr{Sys.Date()}}


\begin{document}

<<setup, include=FALSE, cache=FALSE>>=
options(format.R.blank=FALSE)
options(width=60)
options(continue=" ")
options(replace.assign=TRUE)
options(scipen=8, digits=4)
opts_chunk$set(
  dev="pdf",
  fig.align='center',
  fig.width=7,
  fig.height=4,
  fig.pos='H',
  fig.show='asis',
  out.width='0.99\\linewidth',
  par=TRUE,
  tidy=FALSE,
  tidy.opts=list(width.cutoff=50),
  prompt=FALSE,
  comment=NA
)
set.seed(1)
@

\begin{frame}[fragile]
  \titlepage
\end{frame}

\begin{frame}{Learning Objectives}
\begin{itemize}
\item Density Curves
\item Normal curves
\item QQ-plots
\item Sections 2.5.1, 3.1.1, 3.1.2, 3.1.5, 3.2
\end{itemize}
\end{frame}

\section{Density Curves}

\begin{frame}[fragile]{A histogram of simulated data}
<<echo=FALSE, message=FALSE>>=
library(tidyverse)
simdat <- rnorm(100000)
qplot(simdat, geom = "histogram", bins = 10)
@
\end{frame}

\begin{frame}[fragile]{What if we decrease the binwidth?}
<<echo=FALSE>>=
qplot(simdat, geom = "histogram", bins = 30)
@
\end{frame}

\begin{frame}[fragile]{And more}
<<echo=FALSE>>=
qplot(simdat, geom = "histogram", bins = 80)
@
\end{frame}

\begin{frame}[fragile]{What do you notice?}
<<echo=FALSE>>=
ggplot(data_frame(sims = simdat), aes(sims, ..density..)) +
  geom_histogram(bins = 80) +
  geom_line(stat = "density", lty = 2, col = 2, lwd = 2)
@
Starting to look like a smooth curve!
\end{frame}

\begin{frame}{Density curve}
\begin{itemize}
\item The distributions of many quantitative variables can be approximated by a \alert{density curve}
\end{itemize}
\begin{block}{density curve}
A \alert{density curve} describes the overall pattern of a distribution. The area under the curve and above any range of values is the proportion of all observations that fall in that range. A density cuve is a curve that
\begin{itemize}
\item Is always on or above the horizontal axis.
\item Has area exactly 1 underneath it.
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{Recall: Movie Scores}
Observational units: Movies that sold tickets in 2015.

Variables:
\begin{itemize}
\item \code{rt} Rotten tomatoes score normalized to a 5 point scale.
\item \code{meta} Metacritic score normalized to a 5 point scale.
\item \code{imdb} IMDB score normalized to a 5 point scale.
\item \code{fan} Fandango score.
\end{itemize}
\end{frame}



<<echo = FALSE,message=FALSE>>=
library(tidyverse)
read_csv("../../data/movie.csv") %>%
  select(FILM, RT_norm, Metacritic_norm,
         IMDB_norm, Fandango_Stars) %>%
  transmute(film = FILM, rt = RT_norm, meta = Metacritic_norm,
            imdb = IMDB_norm, fan = Fandango_Stars) ->
  movie
@

\begin{frame}[fragile]{Density of Metacritic scores}
<<>>=
md <- density(movie$meta)
hist(movie$meta, freq = FALSE)
lines(md$x, md$y)
@
\end{frame}

\begin{frame}[fragile]{Using ggplot2}
<<>>=
qplot(movie$meta, ..density.., geom="histogram",
      bins = 15) +
  geom_line(stat = "density")
@
\end{frame}

\begin{frame}{Density example}
<<echo = FALSE>>=
low <- 2
high <- 4
which_good <- md$x >= low & md$x <= high
padx <- c(low, md$x[which_good], high, low)
pady <- c(0, md$y[which_good], 0, 0)
plot(md$x, md$y, xlab = "meta", ylab = "density", type = "l")
polygon(x = padx, y = pady, col = "Blue", border = NA)
@
E.g.: Area of shaded region is approximately the proportion of metracritic scores that falls between \Sexpr{low} and \Sexpr{high}.
\end{frame}

\begin{frame}{Density example}
<<echo = FALSE>>=
low <- 0
high <- 2
which_good <- md$x >= low & md$x <= high
padx <- c(low, md$x[which_good], high, low)
pady <- c(0, md$y[which_good], 0, 0)
plot(md$x, md$y, xlab = "meta", ylab = "density", type = "l")
polygon(x = padx, y = pady, col = "Blue", border = NA)
@
E.g.: Area of shaded region is approximately the proportion of metracritic scores that are less than 2.
\end{frame}

\begin{frame}{Density example}
<<echo = FALSE>>=
low <- 0
high <- 6
which_good <- md$x >= low & md$x <= high
padx <- c(low, md$x[which_good], high, low)
pady <- c(0, md$y[which_good], 0, 0)
plot(md$x, md$y, xlab = "meta", ylab = "density", type = "l")
polygon(x = padx, y = pady, col = "Blue", border = NA)
@
E.g.: Area of shaded region is exactly 1.
\end{frame}

\begin{frame}[fragile]{Smoothness}
Just as you can control the bin-width of histograms, you can control the smoothness (aka ``bandwidth'') of density plots.
<<>>=
md <- density(movie$meta, bw = 0.1)
plot(md)
@
\end{frame}

\begin{frame}[fragile]{More smooth}
<<>>=
md <- density(movie$meta, bw = 0.2)
plot(md)
@
\end{frame}

\begin{frame}[fragile]{More smooth}
<<>>=
md <- density(movie$meta, bw = 0.3)
plot(md)
@
\end{frame}

\begin{frame}[fragile]{Too smooth!}
<<>>=
md <- density(movie$meta, bw = 0.5)
plot(md)
@
\end{frame}

\begin{frame}{Mean and median}
\begin{block}{median}
The \alert{median} of a density curve is the equal-areas point, the point that divides the area under the curve in half.
\end{block}

\begin{block}{mean}
The \alert{mean} of a density curve is the balance point, at which the curve would balance if made of solid material.
\end{block}
\end{frame}

\begin{frame}[fragile]{Median}
<<echo = FALSE>>=
md <- density(movie$meta)
low <- 0
high <- median(movie$meta)
which_good <- md$x >= low & md$x <= high
padx <- c(low, md$x[which_good], high, low)
pady <- c(0, md$y[which_good], 0, 0)
plot(md$x, md$y, xlab = "meta", ylab = "density", type = "l")
polygon(x = padx, y = pady, col = "Blue", border = NA)
mtext(side = 1, text = "M", at = high)
@
Median $M$ is where half of the area is to the left and to the right of $M$.
\end{frame}

\section{Normal Density Curves}

\begin{frame}[fragile]{Recall SAT scores}
A data frame with 1000 observations on the following 6 variables.
\begin{itemize}
\item \code{sex} Gender of the student.
\item \code{SATV} Verbal SAT percentile.
\item \code{SATM} Math SAT percentile.
\item \code{SATSum} Total of verbal and math SAT percentiles.
\item \code{HSGPA} High school grade point average.
\item \code{FYGPA} First year (college) grade point average.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{satGPA}
<<message=FALSE>>=
library(tidyverse)
data(satGPA, package = "openintro")
glimpse(satGPA)
@
\end{frame}

\begin{frame}[fragile]{Bell-shaped curves}
<<>>=
hist(satGPA$SATV, freq = FALSE)
md <- density(satGPA$SATV)
lines(md$x, md$y)
@
Such ``bell-shaped'' curves show up everywhere.
\end{frame}

\begin{frame}{Normal density}
One particular bell-shaped density curve is the normal density.
\begin{block}{normal curve}
The \alert{normal curve} describes the \alert{normal distribution}. It is bell-shaped and is defined by the equation:
$$
f(x|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2\sigma^2}(x - \mu)^2},
$$
where $\mu$ is the mean and $\sigma$ is the standard deviation of the normal distribution.
\end{block}
\end{frame}

\begin{frame}{Facts about the normal density.}
\begin{itemize}
\item Symmetric, unimodal.
\item Completely described by its mean $\mu$ and its standard deviation (or variance) $\sigma$.
\item 1 $\sigma$ from $\mu$ is an inflection point --- a point where the 2nd derivative switches from positive to negative (or vice versa). I.e. transition from concave to convex (or vice versa).
\item Many variables follow a normal distribution (test scores, physical measurements)
\item Many chance processes converge to a normal distribution (more on this later).
\end{itemize}
\end{frame}

\begin{frame}{68-95-99.7 rule}
\begin{block}{68-95-99.7 rule}
In the Normal distribution with mean $\mu$ and standard deviation $\sigma$
\begin{itemize}
\item Approximately 68\% of the observations fall within $\sigma$ of $\mu$
\item Approximately 95\% of the observations fall within $2\sigma$ of $\mu$
\item Approximately 99.7\% of the observations fall within $3\sigma$ of $\mu$
\end{itemize}
This rule does not depend on the values of $\mu$ and $\sigma$.
\end{block}
\end{frame}

\begin{frame}[fragile]{68-95-99.7 rule}
<<echo = FALSE>>=
x <- seq(-3.5, 3.5, length = 500)
y <- dnorm(x)
dat <- data_frame(x = x, y = y)
poly1 <- data.frame(x = c(-1, x[x <= 1 & x >= -1], 1, -1),
                    y = c(0, y[x <= 1 & x >= -1], 0, 0))
poly2 <- data.frame(x = c(-2, x[x <= 2 & x >= -2], 2, -2),
                    y = c(0, y[x <= 2 & x >= -2], 0, 0))
poly3 <- data.frame(x = c(-3, x[x <= 3 & x >= -3], 3, -3),
                    y = c(0, y[x <= 3 & x >= -3], 0, 0))
ggplot(data = dat, aes(x = x, y = y)) +
  geom_line() +
  geom_polygon(data = poly1, aes(x, y), alpha = 0.2, fill = "red") +
  geom_polygon(data = poly2, aes(x, y), alpha = 0.2, fill = "blue") +
  geom_polygon(data = poly3, aes(x, y), alpha = 0.2, fill = "green") +
  ylab("density") +
  ggtitle("68-95-99.7 rule") +
  annotate("text", x = 0.85, y = 0.35, label = "68%") +
  annotate("text", x = 1.8, y = 0.15, label = "95%") +
  annotate("text", x = 2.8, y = 0.04, label = "99.7%") +
  scale_x_continuous(breaks = -3:3) +
  theme_bw()
@
\end{frame}

\begin{frame}{Percentiles}
Use the 68-95-99.7 rule to answer these questions.
\begin{itemize}
\item What percentile is $-3\sigma$? 0.0015
\item What percentile is $-2\sigma$?
\item What percentile is $-1\sigma$?
\item What percentile is $0\sigma$? 0.5
\item What percentile is $1\sigma$?
\item What percentile is $2\sigma$? 0.975
\item What percentile is $3\sigma$?
\end{itemize}
\end{frame}

\section{Checking for normality}

\begin{frame}[fragile]{Clearly not all distributions are normal}
<<echo=FALSE, message=FALSE>>=
read_csv("../../data/trump.csv") ->
  trump
ggplot(trump, aes(x = length)) +
  geom_histogram(bins = 30) +
  ggtitle("Trump's tweet lengths")
@
\end{frame}

\begin{frame}[fragile]{It's sometimes important to check if normality is a valid approximation.}
\begin{itemize}
\item Idea: Is the 68-95-99.7 rule approximately correct for the \code{satGPA} data?
\item More generally, do the percentiles (quantiles) of the data match with the percentiles (quantiles) of the theoretical normal distribution?
\item Compare the $p$th percentile (quantile) of the data and the $p$th percentile (quantile) of a $N(\bar{x}, s^2)$ distribution. If they are pretty close, then normality is a good approximation.
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Look at percentiles (quantiles)}
\footnotesize
<<>>=
mu    <- mean(satGPA$SATV)
sigma <- sd(satGPA$SATV)
qnorm(p = 0.2, mean = mu, sd = sigma)
quantile(x = satGPA$SATV, probs = 0.2)
@
\normalsize
That matches almost exactly, what about other percentiles (quantiles)?
\end{frame}

\begin{frame}[fragile]{More percentiles (quantiles)}
\footnotesize
<<>>=
qnorm(p = 0.4, mean = mu, sd = sigma)
quantile(x = satGPA$SATV, probs = 0.4)
@
\normalsize
\end{frame}

\begin{frame}[fragile]{more percentiles(quantiles)}
\footnotesize
<<>>=
qnorm(p = 0.9, mean = mu, sd = sigma)
quantile(x = satGPA$SATV, probs = 0.9)
@
\normalsize
These are all pretty close!
\end{frame}

\begin{frame}[fragile]{Quantile-quantile plot}
\begin{itemize}
\item Plots the observed quantiles against the quantiles of a $N(\bar{x}, s^2)$ density.
\item If the points lie close to a line, then the normal approximation is approximately correct.
\item Can just plot the observed quantiles against $N(0, 1)$ and look for a straight line (more on why later).
\end{itemize}
\end{frame}

\begin{frame}[fragile]{QQplot}
<<>>=
qqnorm(satGPA$SATV)
qqline(satGPA$SATV)
@
\end{frame}

\begin{frame}[fragile]{qqplot in ggplot2}
<<>>=
qplot(sample = satGPA$SATV, geom = "qq")
@
\end{frame}

\begin{frame}[fragile]{But what does a ``good'' qqplot look like?}
<<echo=FALSE>>=
y <- qnorm(ppoints(nrow(satGPA)))
dftot <- data_frame(x = sort(satGPA$SATV, decreasing = FALSE), y = y)
dftot$sim <- 0
for (index in 1:5) {
  x <- rnorm(nrow(satGPA), mean = mu, sd = sigma)
  df_temp <- data_frame(x = sort(x, decreasing = FALSE), y = y)
  df_temp$sim <- index
  dftot <- bind_rows(dftot, df_temp)
}
dftot$sim <- as.factor(dftot$sim)
ggplot(data = dftot, mapping = aes(x = x, y = y)) +
  geom_point() +
  geom_smooth(method = "lm", lty = 2, col = "red") +
  facet_wrap(~sim) +
  theme_bw() +
  ylab("theoretical quantiles") +
  xlab("observed quantiles") +
  theme(strip.background = element_rect(fill = "white"))
@
Top left is real data, rest are simulated from $N(\bar{x}, s^2)$ --- looks good to me!
\end{frame}

\begin{frame}[fragile]{Problem: Skewed left}
<<echo=FALSE>>=
x <- rgamma(100, 2, 2)
op <- par(mfrow = c(1,2))
hist(x)
qqnorm(x)
qqline(x)
par(op)
@
\end{frame}

\begin{frame}[fragile]{Problem: Skewed right}
<<echo=FALSE>>=
op <- par(mfrow = c(1,2))
hist(-x)
qqnorm(-x)
qqline(-x)
par(op)
@
\end{frame}

\begin{frame}[fragile]{Problem: Outliers}
<<echo=FALSE>>=
x <- c(rnorm(100), 4.5)
op <- par(mfrow = c(1,2))
hist(x)
qqnorm(x)
qqline(x)
par(op)
@
\end{frame}

\begin{frame}[fragile]{Problem: Heavy tails}
<<echo=FALSE>>=
x <- rt(200, 3)
op <- par(mfrow = c(1,2))
hist(x)
qqnorm(x)
qqline(x)
par(op)
@
\end{frame}

\begin{frame}[fragile]{Problem: Light tails}
<<echo=FALSE>>=
x <- runif(100)
op <- par(mfrow = c(1,2))
hist(x)
qqnorm(x)
qqline(x)
par(op)
@
\end{frame}

\end{document}


